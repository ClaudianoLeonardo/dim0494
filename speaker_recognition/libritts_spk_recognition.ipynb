{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f4e9c4",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import random\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756c1bb",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66493e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file, n_mfcc=20):\n",
    "    \"\"\"\n",
    "    Extract MFCC from speech signal.\n",
    "    \"\"\"\n",
    "    s, sr = librosa.load(file, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=s,\n",
    "                                sr=sr,\n",
    "                                n_mfcc=n_mfcc).T\n",
    "    return mfcc\n",
    "\n",
    "def load_data_libritts(file):\n",
    "    \"\"\"\n",
    "    Load training data.\n",
    "    \"\"\"\n",
    "    mfcclist = []\n",
    "    spklist = []\n",
    "    libritts_spklist = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            if '.wav' in line:\n",
    "                info = line.strip().split(',')\n",
    "                wavfile = info[1]\n",
    "                speaker = info[-1]\n",
    "                libritts_spk = wavfile.replace('train/','').split('_')[0]\n",
    "                spklist.append(speaker)\n",
    "                libritts_spklist.append(libritts_spk)\n",
    "                mfcc = get_mfcc(wavfile, n_mfcc=40)\n",
    "                mfcclist.append(mfcc)\n",
    "    return spklist, mfcclist, libritts_spklist\n",
    "\n",
    "def load_test_data_libritts(file, nmfcc=40):\n",
    "    \"\"\"\n",
    "    Load test data.\n",
    "    \"\"\"\n",
    "    mfcclist = []\n",
    "    libritts_spklist = []\n",
    "    idlist = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            if '.wav' in line:            \n",
    "                info = line.strip().split(',')\n",
    "                idspk = info[0]\n",
    "                wavfile = info[1]\n",
    "                libritts_spk = wavfile.replace('test/','').split('_')[0]\n",
    "                libritts_spklist.append(libritts_spk)\n",
    "                idlist.append(idspk)\n",
    "                mfcc = get_mfcc(wavfile, n_mfcc=nmfcc)\n",
    "                mfcclist.append(mfcc)\n",
    "    return libritts_spklist, mfcclist, idlist\n",
    "\n",
    "def preprocess_input(spklist, mfcclist, libritts_spklist, pad_length=None):\n",
    "    \"\"\"\n",
    "    Preprocess training input.\n",
    "    \"\"\"\n",
    "    speakers = {}\n",
    "    for spk, libritts_spk in zip(spklist, libritts_spklist):\n",
    "        speakers[libritts_spk]=spk\n",
    "    X = keras.preprocessing.sequence.pad_sequences(mfcclist, maxlen=pad_length)\n",
    "    y = keras.utils.to_categorical(spklist, dtype='float32')\n",
    "    return X, y, speakers\n",
    "\n",
    "def preprocess_test(test_libritts_spklist, test_mfcclist, speakers, pad_length=None):\n",
    "    \"\"\"\n",
    "    Preprocess test input.\n",
    "    \"\"\"\n",
    "    test_spklist = []\n",
    "    for spk in test_libritts_spklist:\n",
    "        test_spklist.append(int(speakers.get(spk)))\n",
    "    X_test = keras.preprocessing.sequence.pad_sequences(test_mfcclist, maxlen=pad_length)\n",
    "    y_test = keras.utils.to_categorical(test_spklist, num_classes=90, dtype='float32')\n",
    "    return X_test, y_test, test_spklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a5784",
   "metadata": {},
   "source": [
    "# load training data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data in memory\n",
    "# NOTE: this is not a good practice\n",
    "spklist, mfcclist, libritts_spk = load_data_libritts('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "X, y, speakers = preprocess_input(spklist, mfcclist, libritts_spk)\n",
    "print(f'Shape of the input matrix: {X.shape}')\n",
    "print(f'Shape of the label matrix: {y.shape}')\n",
    "print(f'LibriTTS speaker ids and indices: {speakers}')\n",
    "num_mfcc = X.shape[2]\n",
    "num_speakers = y.shape[1]\n",
    "print(f'Number of speakers: {num_speakers}')\n",
    "print(f'Number of effective speakers: {len(speakers)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea13e4",
   "metadata": {},
   "source": [
    "# build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sequential model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv1D(80, 7, padding='same', input_shape=(None, num_mfcc)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling1D(7),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Conv1D(120, 7, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling1D(7),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Conv1D(160, 7, padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling1D(7),\n",
    "    keras.layers.LeakyReLU(0.2),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "    keras.layers.Dense(num_speakers, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1.0e-8\n",
    "DECAY = 0.0\n",
    "NUM_EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642efbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=LR,\n",
    "                            beta_1=BETA1,\n",
    "                            beta_2=BETA2,\n",
    "                            epsilon=EPSILON,\n",
    "                            decay=DECAY)\n",
    "\n",
    "# loss\n",
    "loss = keras.losses.categorical_crossentropy\n",
    "\n",
    "# metrics to be considered during training\n",
    "met = [keras.metrics.categorical_accuracy]\n",
    "\n",
    "# callbacks: early stop and model checkpoint (save best model)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='categorical_accuracy',\n",
    "        patience=10),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='best_model.hdf5',\n",
    "        monitor='val_categorical_accuracy',\n",
    "        save_best_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation\n",
    "model.compile(optimizer=opt, loss=loss, metrics=met)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05bd33",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9343aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "history = model.fit(X,\n",
    "                y,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                validation_split=0.2,\n",
    "                callbacks=callbacks_list,\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d4f8a7",
   "metadata": {},
   "source": [
    "# check if the training went well: learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a0a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curves\n",
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "# losses\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "# accuracies\n",
    "acc_values = history_dict['categorical_accuracy']\n",
    "val_acc_values = history_dict['val_categorical_accuracy']\n",
    "\n",
    "epochs = range(len(loss_values))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2,1, figsize=(10,10))\n",
    "\n",
    "ax1.plot(epochs, loss_values, 'bo', label=\"Training Loss\")\n",
    "ax1.plot(epochs, val_loss_values, 'b', label=\"Validation Loss\")\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss Value')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(epochs, acc_values, 'ro', label=\"Training Accuracy\")\n",
    "ax2.plot(epochs, val_acc_values, 'r', label=\"Validation Accuracy\")\n",
    "ax2.set_title('Training and Validation Accuraccy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1e0d0c",
   "metadata": {},
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719cb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc198cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_libritts_spklist, test_mfcclist, test_idlist = load_test_data_libritts('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess test data\n",
    "X_test, y_test, test_spklist = preprocess_test(test_libritts_spklist, test_mfcclist, speakers)\n",
    "print(f'Shape of the input matrix: {X.shape}')\n",
    "print(f'Shape of the label matrix: {y.shape}')\n",
    "num_test_speakers = y_test.shape[1]\n",
    "print(f'Number of test speakers: {num_test_speakers}')\n",
    "print(f'Number of effective test speakers: {len(set(test_spklist))}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that we have the speaker ids from the sentence names, evaluate the model in the test set\n",
    "eval = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "print(f'Accuracy in the test set: {eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions using the test set\n",
    "y_pred = model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels and shows classification report\n",
    "labels_test = np.argmax(y_test, axis=1)\n",
    "labels_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970eda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "cm = confusion_matrix(labels_test, labels_pred)\n",
    "df_cm = pd.DataFrame(cm, range(84), range(84))\n",
    "plt.figure(figsize=(15,8))\n",
    "sn.set(font_scale=0.8) # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 1}) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec546d",
   "metadata": {},
   "source": [
    "# write the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build output for submission\n",
    "output_info = ['id,speaker']\n",
    "for i, idspk in enumerate(test_idlist):\n",
    "    pred_label = np.argmax(y_pred[i], axis=-1)\n",
    "    output_info.append(f'{idspk},{pred_label}')\n",
    "\n",
    "submission_file = 'submission_v003.csv'\n",
    "\n",
    "# write submission\n",
    "with open(submission_file, 'w') as f:\n",
    "    for data in output_info:\n",
    "        f.write(data+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
